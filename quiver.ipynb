{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import  Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn_evaluation import plot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import model_from_json\n",
    "from quiver_engine import server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result/test_nwh/model_architecture.json', 'r') as f:\n",
    "    model = model_from_json(f.read())\n",
    "\n",
    "model.load_weights('./result/test_nwh/weights-35-0.78.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting webserver from: /usr/local/lib/python3.6/site-packages/quiver_engine-0.1.4.1.5-py3.6.egg/quiver_engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "::1 - - [2018-06-06 12:56:09] \"GET /model HTTP/1.1\" 200 3365 0.005570\n",
      "::1 - - [2018-06-06 12:56:09] \"GET /inputs HTTP/1.1\" 200 23101 0.005762\n",
      "::1 - - [2018-06-06 12:56:09] \"GET /input-file/conv2d_7_0_conv2d_7_0_test_img0.png.png.png HTTP/1.1\" 200 2926 0.003043\n",
      "::1 - - [2018-06-06 12:56:09] \"GET /input-file/conv2d_7_0_test_img63.png.png HTTP/1.1\" 200 2392 0.002921\n",
      "::1 - - [2018-06-06 12:56:09] \"GET /input-file/conv2d_7_0_test_img64.png.png HTTP/1.1\" 200 2408 0.002706\n",
      "::1 - - [2018-06-06 12:56:09] \"GET /input-file/conv2d_7_0_test_img83.png.png HTTP/1.1\" 200 2208 0.002692\n",
      "::1 - - [2018-06-06 12:56:09] \"GET /input-file/conv2d_7_0_test_img89.png.png HTTP/1.1\" 200 2268 0.003234\n",
      "::1 - - [2018-06-06 12:56:09] \"GET /input-file/conv2d_7_0_test_img94.png.png HTTP/1.1\" 200 2266 0.003168\n",
      "::1 - - [2018-06-06 12:56:09] \"GET /input-file/conv2d_7_0_test_img95.png.png HTTP/1.1\" 200 2269 0.003021\n",
      "::1 - - [2018-06-06 12:56:09] \"GET /input-file/conv2d_7_0_test_img96.png.png HTTP/1.1\" 200 2376 0.004048\n",
      "::1 - - [2018-06-06 12:56:09] \"GET /input-file/conv2d_7_0_test_img97.png.png HTTP/1.1\" 200 2399 0.004772\n",
      "[2018-06-06 12:56:17,486] ERROR in app: Exception on /predict/test_img99.png [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sun/Library/Python/3.6/lib/python/site-packages/flask/app.py\", line 2292, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/sun/Library/Python/3.6/lib/python/site-packages/flask/app.py\", line 1815, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/sun/Library/Python/3.6/lib/python/site-packages/flask_cors/extension.py\", line 161, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "  File \"/Users/sun/Library/Python/3.6/lib/python/site-packages/flask/app.py\", line 1718, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/Users/sun/Library/Python/3.6/lib/python/site-packages/flask/_compat.py\", line 35, in reraise\n",
      "    raise value\n",
      "  File \"/Users/sun/Library/Python/3.6/lib/python/site-packages/flask/app.py\", line 1813, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/sun/Library/Python/3.6/lib/python/site-packages/flask/app.py\", line 1799, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/quiver_engine-0.1.4.1.5-py3.6.egg/quiver_engine/server.py\", line 121, in get_prediction\n",
      "    top\n",
      "  File \"/usr/local/lib/python3.6/site-packages/quiver_engine-0.1.4.1.5-py3.6.egg/quiver_engine/util.py\", line 49, in decode_predictions\n",
      "    return decode_imagenet_predictions(preds, top)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/quiver_engine-0.1.4.1.5-py3.6.egg/quiver_engine/imagenet_utils.py\", line 51, in decode_imagenet_predictions\n",
      "    'Found array with shape: ' + str(preds.shape))\n",
      "ValueError: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! you didn't pass your own set of classes for the model therefore imagenet classes are used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "::1 - - [2018-06-06 12:56:17] \"GET /predict/test_img99.png HTTP/1.1\" 500 444 0.013555\n",
      "/usr/local/lib/python3.6/site-packages/quiver_engine-0.1.4.1.5-py3.6.egg/quiver_engine/layer_result_generators.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"co..., outputs=Tensor(\"co...)`\n",
      "  output=model.get_layer(layer_name).output\n",
      "::1 - - [2018-06-06 12:56:17] \"GET /layer/conv2d_8/test_img99.png HTTP/1.1\" 200 174 0.026976\n",
      "::1 - - [2018-06-06 12:56:17] \"GET /temp-file/conv2d_8_0_test_img99.png.png HTTP/1.1\" 200 1399 0.001345\n",
      "::1 - - [2018-06-06 12:56:19] \"GET /layer/conv2d_9/test_img99.png HTTP/1.1\" 200 174 0.022306\n",
      "::1 - - [2018-06-06 12:56:19] \"GET /temp-file/conv2d_9_0_test_img99.png.png HTTP/1.1\" 200 974 0.057445\n",
      "::1 - - [2018-06-06 12:56:24] \"GET /layer/conv2d_8/test_img99.png HTTP/1.1\" 200 174 0.017592\n",
      "::1 - - [2018-06-06 12:56:25] \"GET /layer/conv2d_7/test_img99.png HTTP/1.1\" 200 174 0.015792\n",
      "::1 - - [2018-06-06 12:56:25] \"GET /temp-file/conv2d_7_0_test_img99.png.png HTTP/1.1\" 200 2399 0.001359\n"
     ]
    }
   ],
   "source": [
    "server.launch(model,temp_folder='./save_data/img', input_folder='./save_data/img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('./save_data/img/test_img0.png', grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = np.expand_dims(image.img_to_array(img), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 96, 96, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_config(model):\n",
    "    '''\n",
    "        returns a tuple (inputDimensions, numChannels)\n",
    "    '''\n",
    "\n",
    "    return (\n",
    "        model.get_input_shape_at(0)[1:3],\n",
    "        model.get_input_shape_at(0)[0]\n",
    "    ) if K.image_dim_ordering() == 'th' else (\n",
    "        #tf ordering\n",
    "        model.get_input_shape_at(0)[2:4],\n",
    "        model.get_input_shape_at(0)[1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_input_shape, input_channels = get_input_config(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
