{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ini/workspace/sunbin/do-neural-networks-learn-faus-iccvw-2015/data_scripts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workbookDir: /home/ini/workspace/sunbin/do-neural-networks-learn-faus-iccvw-2015/data_scripts\n"
     ]
    }
   ],
   "source": [
    "if not 'workbookDir' in globals():\n",
    "    workbookDir = os.getcwd()\n",
    "print('workbookDir: ' + workbookDir)\n",
    "os.chdir(workbookDir)  # If you changed the current working dir, this will take you back to the workbook dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CKPlusCondenser(object):\n",
    "    def __init__(self, original_dataset_path, condensed_dataset_path):\n",
    "        if os.path.exists(condensed_dataset_path):\n",
    "            print 'Condensed Dataset detected.'\n",
    "            print 'Removing it.'\n",
    "            shutil.rmtree(condensed_dataset_path)\n",
    "        print 'Copying original dataset to new condensed dataset path.'\n",
    "        shutil.copytree(original_dataset_path, condensed_dataset_path)\n",
    "\n",
    "        self.image_path = os.path.join(condensed_dataset_path,\n",
    "                                       'cohn-kanade-images')\n",
    "        self.label_path = os.path.join(condensed_dataset_path,\n",
    "                                       'Emotion_labels')\n",
    "        self.facs_path = os.path.join(condensed_dataset_path,\n",
    "                                       'FACS_labels')\n",
    "\n",
    "    def run(self):\n",
    "        print '\\nCondensing CK+ Dataset: '\n",
    "        self.condense_dataset()\n",
    "        print '\\nCondensed CK+ Dataset Statistics: '\n",
    "        self.compute_dataset_statistics()\n",
    "\n",
    "    def condense_dataset(self):\n",
    "        # Get list of folders with no label file\n",
    "        no_label_list = self.find_empty_folders(self.label_path)\n",
    "        print '%d empty sequences to be removed.' % len(no_label_list)\n",
    "\n",
    "        # Remove image sequence if label folder exists but is empty\n",
    "        print '\\nRemoving image sequence folders that have no label.'\n",
    "        self.remove_image_sequences(self.image_path,\n",
    "                                    self.label_path,\n",
    "                                    no_label_list)\n",
    "\n",
    "        # Remove empty folders in label directory\n",
    "        print '\\nRemoving empty label folders.'\n",
    "        self.remove_folders_in_list(no_label_list)\n",
    "\n",
    "        # Keep only the first and last three images in each sequence\n",
    "        print '\\nKeeping only the first and ' \\\n",
    "            'last three images in each sequence.'\n",
    "        self.reduce_all_image_sequences(self.image_path)\n",
    "\n",
    "    def find_empty_folders(self, label_path):\n",
    "        folder_list = []\n",
    "        for dirpath, dirs, files in os.walk(label_path):\n",
    "            if not dirs and not files:\n",
    "                folder_list.append(dirpath)\n",
    "        return sorted(folder_list)\n",
    "\n",
    "    def remove_image_sequences(self, image_path, label_path, no_label_list):\n",
    "        mismatched_image_paths = self.find_image_label_mismatch(image_path,\n",
    "                                                                label_path)\n",
    "        self.remove_folders_in_list(mismatched_image_paths)\n",
    "\n",
    "        # Gather folder extensions that have no label file\n",
    "        folder_extension_list = []\n",
    "        for folder_path in no_label_list:\n",
    "            path_split_list = folder_path.split(os.sep)\n",
    "            folder_extension = os.path.join(path_split_list[-2],\n",
    "                                            path_split_list[-1])\n",
    "            folder_extension_list.append(folder_extension)\n",
    "\n",
    "        # Prepend the image_path to get the image sequence location\n",
    "        image_sequence_path_list = [os.path.join(image_path, ext) for ext\n",
    "                                    in folder_extension_list]\n",
    "\n",
    "        # Remove image sequences in list\n",
    "        self.remove_folders_in_list(image_sequence_path_list)\n",
    "\n",
    "    def find_image_label_mismatch(self, image_path, label_path):\n",
    "        mismatched_image_paths = []\n",
    "        image_subj_list = sorted(os.listdir(image_path))\n",
    "\n",
    "        for subj in image_subj_list:\n",
    "            seq_list = sorted(os.listdir(os.path.join(image_path, subj)))\n",
    "            for seq in seq_list:\n",
    "                if seq == '.DS_Store':\n",
    "                    os.remove(os.path.join(image_path, subj, seq))\n",
    "                    continue\n",
    "\n",
    "                seq_label_path = os.path.join(label_path, subj, seq)\n",
    "                if not os.path.exists(seq_label_path):\n",
    "                    seq_path = os.path.join(image_path, subj, seq)\n",
    "                    mismatched_image_paths.append(seq_path)\n",
    "\n",
    "        print 'There are %d mismatched files.' % len(mismatched_image_paths)\n",
    "        return mismatched_image_paths\n",
    "\n",
    "    def remove_folders_in_list(self, folder_list):\n",
    "        #\n",
    "        # Helper function to remove folders listed in folder_list\n",
    "        #\n",
    "        for i, folder_path in enumerate(folder_list):\n",
    "            # print '%d: Removing --- %s' % (i, folder_path)\n",
    "            if os.path.exists(folder_path):\n",
    "                shutil.rmtree(folder_path)\n",
    "            else:\n",
    "                print 'Folder %s does not exist' % (folder_path)\n",
    "            time.sleep(0.1)\n",
    "\n",
    "            parent_path, ext = os.path.split(folder_path)\n",
    "            # Check if parent folder is empty\n",
    "            if os.listdir(parent_path) == []:\n",
    "                # If so, remove it\n",
    "                # print 'Parent dir %s is empty' % parent_path\n",
    "                shutil.rmtree(parent_path)\n",
    "            elif os.listdir(parent_path) == ['.DS_Store']:\n",
    "                # print '.DS_Store file is present. Removing...'\n",
    "                os.remove(os.path.join(parent_path, '.DS_Store'))\n",
    "                # print 'Now parent dir %s is empty' % parent_path\n",
    "                shutil.rmtree(parent_path)\n",
    "\n",
    "    def reduce_all_image_sequences(self, image_path):\n",
    "        subj_folder_list = sorted(os.listdir(image_path))\n",
    "        for subj_folder in subj_folder_list:\n",
    "            subj_path = os.path.join(image_path, subj_folder)\n",
    "            print 'Processing: ', subj_path\n",
    "            seq_folder_list = sorted(os.listdir(subj_path))\n",
    "            for seq_folder in seq_folder_list:\n",
    "                seq_path = os.path.join(subj_path, seq_folder)\n",
    "                if not os.path.isdir(seq_path):\n",
    "                    continue\n",
    "\n",
    "                self.reduce_single_sequence(seq_path)\n",
    "\n",
    "    def reduce_single_sequence(self, path):\n",
    "        file_list = sorted(os.listdir(path))\n",
    "        for f in file_list:\n",
    "            if f == '.DS_Store':\n",
    "                # print 'Found it!'\n",
    "                os.remove(os.path.join(path, f))\n",
    "\n",
    "        if len(file_list) < 4:\n",
    "            print 'Folder contains < 4 files. No reduction needed.'\n",
    "            return\n",
    "\n",
    "        remove_list = file_list[1:-3]\n",
    "        for remove_file in remove_list:\n",
    "            # print 'Remove ', remove_file\n",
    "            os.remove(os.path.join(path, remove_file))\n",
    "\n",
    "    def count_num_sequences(self, path):\n",
    "        subj_folder_list = sorted(os.listdir(path))\n",
    "        num_subj_total = len(subj_folder_list)\n",
    "\n",
    "        num_seq_per_subj = []\n",
    "        num_files_per_subj = []\n",
    "        for folder in subj_folder_list:\n",
    "            if folder == '.DS_Store':\n",
    "                continue\n",
    "            seq_list = os.listdir(os.path.join(path, folder))\n",
    "            seq_list = [s for s in seq_list if s != '.DS_Store']\n",
    "            num_sequences = len(seq_list)\n",
    "            num_seq_per_subj.append(num_sequences)\n",
    "            for seq in seq_list:\n",
    "                num_files = len(os.listdir(os.path.join(path, folder, seq)))\n",
    "                num_files_per_subj.append(num_files)\n",
    "\n",
    "        num_seq_total = numpy.sum(num_seq_per_subj)\n",
    "        return num_subj_total, num_seq_total\n",
    "\n",
    "    def compute_dataset_statistics(self):\n",
    "        num_subjects, num_sequences = self.count_num_sequences(self.image_path)\n",
    "        print 'Total Number of Image Sequences: %d' % num_sequences\n",
    "\n",
    "        _, num_label_sequences = self.count_num_sequences(self.label_path)\n",
    "        print 'Total Number of Label Sequences: %d' % num_label_sequences\n",
    "\n",
    "        # Number of sequences that have corresponding labels in Emotion_labels\n",
    "        glob_label_path = os.path.join(self.label_path, '*/*/*.txt')\n",
    "        num_label_files = len(glob.glob(glob_label_path))\n",
    "        print 'Number of sequences with correponding label ' \\\n",
    "            '.txt file: %d' % num_label_files\n",
    "\n",
    "        print 'Total Number of Subjects: %d' % num_subjects\n",
    "\n",
    "        glob_image_path = os.path.join(self.image_path, '*/*/*.png')\n",
    "        num_images_total = len(glob.glob(glob_image_path))\n",
    "        print 'Number of image files: %d' % num_images_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CKPlusFaceCropper(object):\n",
    "    def __init__(self, input_path):\n",
    "        print '\\nDetecting and Cropping Faces'\n",
    "        self.input_path = input_path\n",
    "        self.image_path = os.path.join(input_path, 'cohn-kanade-images')\n",
    "\n",
    "    def run(self):\n",
    "        self.crop_and_align_all_faces(self.image_path)\n",
    "\n",
    "    def write_list_to_file(self, file_path, item_list):\n",
    "        f = open(file_path, 'wb')\n",
    "        for item in item_list:\n",
    "            f.write(item+'\\n')\n",
    "        f.close()\n",
    "\n",
    "    def crop_and_align_all_faces(self, path):\n",
    "        output_img_size = (96, 96)\n",
    "        missed_faces = []\n",
    "\n",
    "        all_image_paths = sorted(glob.glob(os.path.join(path, '*/*/*.png')))\n",
    "        # print all_image_paths[0:20]\n",
    "\n",
    "        for image_file_path in all_image_paths:\n",
    "            # print 'Detecting Face: %s' % image_file_path\n",
    "            I, success_flag = self.process_single_image(\n",
    "                                                   image_file_path,\n",
    "                                                   output_img_size)\n",
    "            if not success_flag:\n",
    "                missed_faces.append(image_file_path)\n",
    "            I = numpy.squeeze(I, axis=2)\n",
    "            skimage.io.imsave(os.path.join(image_file_path), I)\n",
    "\n",
    "        print 'Missed Faces: ', sorted(missed_faces)\n",
    "        missed_faces_file_path = os.path.join(self.input_path,\n",
    "                                              'missed_faces.txt')\n",
    "        self.write_list_to_file(missed_faces_file_path, missed_faces)\n",
    "\n",
    "    def process_single_image(self, image_file_path, output_img_size):\n",
    "            # Read in the image\n",
    "            I = skimage.io.imread(image_file_path)\n",
    "\n",
    "            # If image was in color:\n",
    "            if len(I.shape) == 3:\n",
    "                I = skimage.color.rgb2gray(I)\n",
    "                I *= 255\n",
    "                I = I.astype('uint8')\n",
    "\n",
    "            if len(I.shape) != 3:\n",
    "                I = I[:, :, numpy.newaxis]\n",
    "\n",
    "            # Detect face and crop it out\n",
    "            I_crop, success_flag = self.detect_crop_face(I)\n",
    "            #print I_crop.dtype, I_crop.min(), I_crop.max()\n",
    "\n",
    "            # If face was successfully detected.\n",
    "            # Align face in 96x96 image\n",
    "            if success_flag:\n",
    "                I_out = I_crop\n",
    "                I_out = numpy.uint8(skimage.transform.resize(I_out, (96, 96), preserve_range=True))\n",
    "                #print I_out.dtype, I_out.min(), I_out.max()\n",
    "            else:\n",
    "                I_out = I_crop\n",
    "\n",
    "            return I_out, success_flag\n",
    "\n",
    "    def detect_crop_face(self, I):\n",
    "        success_flag = False\n",
    "        face_detector = FaceDetector(scale_factor=1.3, min_neighbors=5,\n",
    "                                     min_size_scalar=0.5, max_size_scalar=0.8)\n",
    "        faces = face_detector.detect_faces(I)\n",
    "\n",
    "        # If face was not detected:\n",
    "        if len(faces) == 0:\n",
    "            # Try with more lenient conditions\n",
    "            face_detector = FaceDetector(scale_factor=1.3,\n",
    "                                         min_neighbors=3,\n",
    "                                         min_size_scalar=0.5,\n",
    "                                         max_size_scalar=0.8)\n",
    "            faces = face_detector.detect_faces(I)\n",
    "            if len(faces) == 0:\n",
    "                print 'Missed the face!'\n",
    "                return I, success_flag\n",
    "\n",
    "        success_flag = True\n",
    "        I_crop = face_detector.crop_face_out(I, faces[0])\n",
    "        return I_crop, success_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CKPlusNumpyFileGenerator(object):\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = os.path.join(save_path, 'npy_files')\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "\n",
    "        self.image_path = os.path.join(save_path, 'cohn-kanade-images')\n",
    "        self.label_path = os.path.join(save_path, 'Emotion_labels')\n",
    "        self.facs_path = os.path.join(save_path, 'FACS_labels')\n",
    "\n",
    "    def run(self):\n",
    "        print '\\nSaving CK+ images and labels to .npy files.'\n",
    "\n",
    "        # Get number of images\n",
    "        glob_image_path = os.path.join(self.image_path, '*/*/*.png')\n",
    "        num_samples = len(glob.glob(glob_image_path))\n",
    "\n",
    "        X, y, facs, subjs = self.make_data_label_mats(self.image_path,\n",
    "                                                self.label_path,\n",
    "                                                self.facs_path,\n",
    "                                                num_samples)\n",
    "        folds = self.make_folds(subjs)\n",
    "\n",
    "        self.save_out_data(self.save_path, X, y, facs, subjs, folds)\n",
    "\n",
    "    def make_data_label_mats(self, all_images_path,\n",
    "                             all_labels_path, all_facs_path, num_samples):\n",
    "        # Initialize the data of interest\n",
    "        image_shape = (96, 96, 1)\n",
    "        X = numpy.zeros((num_samples, image_shape[2],\n",
    "                         image_shape[0], image_shape[1]), dtype='uint8')\n",
    "        y = numpy.zeros((num_samples), dtype='int32')\n",
    "        facs = numpy.zeros((num_samples, 10), dtype='int32')\n",
    "        all_subjs = numpy.zeros((num_samples), dtype='int32')\n",
    "\n",
    "        total_sample_count = 0\n",
    "        subj_list = sorted(os.listdir(all_images_path))\n",
    "\n",
    "        # For each subject folder:\n",
    "        for i, subj in enumerate(subj_list):\n",
    "            print 'Subject: %d - %s' % (i, subj)\n",
    "\n",
    "            # For each individual sequence in the subject folder:\n",
    "            seq_path = os.path.join(all_images_path, subj)\n",
    "            seq_list = sorted(os.listdir(seq_path))\n",
    "            for j, seq in enumerate(seq_list):\n",
    "                # Get the images of the sequence and the emotion label\n",
    "                images = self.read_images(all_images_path, subj, seq,\n",
    "                                          image_shape)\n",
    "                label = self.read_label(all_labels_path, subj, seq)\n",
    "                label_vec = numpy.array([0, label, label, label])\n",
    "\n",
    "                facs = self.read_facs(all_facs_path, subj, seq)\n",
    "                facs_vec = numpy.array([0, facs, facs, facs])\n",
    "\n",
    "                index_slice = slice(total_sample_count,\n",
    "                                    total_sample_count+len(images))\n",
    "                X[index_slice] = images\n",
    "                y[index_slice] = label_vec\n",
    "                facs[index_slice] = facs_vec\n",
    "                all_subjs[index_slice] = i\n",
    "                total_sample_count += len(images)\n",
    "\n",
    "        return X, y, facs, all_subjs\n",
    "\n",
    "    def read_images(self, all_images_path, subj, seq, image_shape):\n",
    "        image_file_path = os.path.join(all_images_path, subj, seq)\n",
    "        image_files = sorted(os.listdir(image_file_path))\n",
    "        num_images = len(image_files)\n",
    "\n",
    "        images = numpy.zeros((num_images, image_shape[2],\n",
    "                              image_shape[0], image_shape[1]))\n",
    "        for i, image_file in enumerate(image_files):\n",
    "            # print image_file\n",
    "            I = skimage.io.imread(os.path.join(image_file_path, image_file))\n",
    "            I = I[:, :, numpy.newaxis]\n",
    "            images[i, :, :, :] = I.transpose(2, 0, 1)\n",
    "\n",
    "        return images\n",
    "\n",
    "    def read_label(self, all_labels_path, subj, seq):\n",
    "        label_file_path = os.path.join(all_labels_path, subj, seq)\n",
    "        label_file = os.listdir(label_file_path)[0]\n",
    "        f = open(os.path.join(label_file_path, label_file))\n",
    "        label = f.read()\n",
    "        f.close()\n",
    "        # print label\n",
    "        label = int(float(label))\n",
    "\n",
    "        return label\n",
    "\n",
    "    def read_facs(self, all_facs_path, subj, seq):\n",
    "        facs_file_path = os.path.join(all_facs_path, subj, seq)\n",
    "        facs_file = os.listdir(facs_file_path)[0]\n",
    "        f = open(os.path.join(facs_file_path, facs_file))\n",
    "        facs_set = set()\n",
    "        for line in f:\n",
    "            if line:\n",
    "                facs_label = map(int,line.split(' '))\n",
    "                facs_set.update(facs_label)\n",
    "        f.close()\n",
    "        facs_list = list(facs_set)\n",
    "        facs = numpy.zeros(10)\n",
    "        facs[:len(facs_list)] = facs_list\n",
    "        \n",
    "        return facs\n",
    "\n",
    "\n",
    "        return label\n",
    "    def make_folds(self, subjs, num_folds=10):\n",
    "        print '\\nMaking the folds.'\n",
    "        folds = numpy.zeros((subjs.shape), dtype='int32')\n",
    "        num_subj = len(numpy.unique(subjs))\n",
    "\n",
    "        for i in range(num_folds):\n",
    "            subjs_in_fold = numpy.arange(i, num_subj, 10)\n",
    "            print 'Subjs in fold %d: %s' % (i, subjs_in_fold)\n",
    "\n",
    "            indices = numpy.hstack(\n",
    "                [numpy.where(subjs == j)[0] for j in subjs_in_fold])\n",
    "            folds[indices] = i\n",
    "\n",
    "        print 'Number of samples/fold: %s' % numpy.histogram(folds,\n",
    "                                                             bins=10)[0]\n",
    "\n",
    "        return folds\n",
    "\n",
    "    def save_out_data(self, path, X, y, facs, subjs, folds):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        numpy.save(os.path.join(path, 'X.npy'), X)\n",
    "        numpy.save(os.path.join(path, 'y.npy'), y)\n",
    "        numpy.save(os.path.join(path, 'facs.npy'), facs)\n",
    "        numpy.save(os.path.join(path, 'subjs.npy'), subjs)\n",
    "        numpy.save(os.path.join(path, 'folds.npy'), folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetector(object):\n",
    "    def __init__(self, scale_factor=1.3, min_neighbors=5,\n",
    "                 min_size_scalar=0.25, max_size_scalar=0.75):\n",
    "        module_path = os.path.dirname(__file__)\n",
    "        classifier_path = os.path.join(module_path,\n",
    "                                       'haarcascade_frontalface_default.xml')\n",
    "        self.detector = cv2.CascadeClassifier(classifier_path)\n",
    "        if self.detector.empty():\n",
    "            raise Exception('Classifier xml file was not found.')\n",
    "        self.scale_factor = scale_factor\n",
    "        self.min_neighbors = min_neighbors\n",
    "        self.min_size_scalar = min_size_scalar\n",
    "        self.max_size_scalar = max_size_scalar\n",
    "        # print self.detector\n",
    "\n",
    "    def detect_faces(self, I):\n",
    "        height, width, num_channels = I.shape\n",
    "        min_dim = numpy.min([height, width])\n",
    "        min_size = (int(min_dim*self.min_size_scalar),\n",
    "                    int(min_dim*self.min_size_scalar))\n",
    "        max_size = (int(min_dim*self.max_size_scalar),\n",
    "                    int(min_dim*self.max_size_scalar))\n",
    "\n",
    "        faces = self.detector.detectMultiScale(I, self.scale_factor,\n",
    "                                               self.min_neighbors, 0,\n",
    "                                               min_size,\n",
    "                                               max_size)\n",
    "        return faces\n",
    "\n",
    "    def crop_face_out(self, I, loc):\n",
    "        (x, y, w, h) = loc\n",
    "        I_crop = I[y:y+h, x:x+w, :]\n",
    "        return I_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condensed Dataset detected.\n",
      "Removing it.\n",
      "Copying original dataset to new condensed dataset path.\n",
      "\n",
      "Condensing CK+ Dataset: \n",
      "255 empty sequences to be removed.\n",
      "\n",
      "Removing image sequence folders that have no label.\n",
      "There are 11 mismatched files.\n",
      "\n",
      "Removing empty label folders.\n",
      "\n",
      "Keeping only the first and last three images in each sequence.\n",
      "Processing:  ../save_data/cohn-kanade-images/S005\n",
      "Processing:  ../save_data/cohn-kanade-images/S010\n",
      "Processing:  ../save_data/cohn-kanade-images/S011\n",
      "Processing:  ../save_data/cohn-kanade-images/S014\n",
      "Processing:  ../save_data/cohn-kanade-images/S022\n",
      "Processing:  ../save_data/cohn-kanade-images/S026\n",
      "Processing:  ../save_data/cohn-kanade-images/S028\n",
      "Processing:  ../save_data/cohn-kanade-images/S029\n",
      "Processing:  ../save_data/cohn-kanade-images/S032\n",
      "Processing:  ../save_data/cohn-kanade-images/S034\n",
      "Processing:  ../save_data/cohn-kanade-images/S035\n",
      "Processing:  ../save_data/cohn-kanade-images/S037\n",
      "Processing:  ../save_data/cohn-kanade-images/S042\n",
      "Processing:  ../save_data/cohn-kanade-images/S044\n",
      "Processing:  ../save_data/cohn-kanade-images/S045\n",
      "Processing:  ../save_data/cohn-kanade-images/S046\n",
      "Processing:  ../save_data/cohn-kanade-images/S050\n",
      "Processing:  ../save_data/cohn-kanade-images/S051\n",
      "Processing:  ../save_data/cohn-kanade-images/S052\n",
      "Processing:  ../save_data/cohn-kanade-images/S053\n",
      "Processing:  ../save_data/cohn-kanade-images/S054\n",
      "Processing:  ../save_data/cohn-kanade-images/S055\n",
      "Processing:  ../save_data/cohn-kanade-images/S056\n",
      "Processing:  ../save_data/cohn-kanade-images/S057\n",
      "Processing:  ../save_data/cohn-kanade-images/S058\n",
      "Processing:  ../save_data/cohn-kanade-images/S059\n",
      "Processing:  ../save_data/cohn-kanade-images/S060\n",
      "Processing:  ../save_data/cohn-kanade-images/S061\n",
      "Processing:  ../save_data/cohn-kanade-images/S062\n",
      "Processing:  ../save_data/cohn-kanade-images/S063\n",
      "Processing:  ../save_data/cohn-kanade-images/S064\n",
      "Processing:  ../save_data/cohn-kanade-images/S065\n",
      "Processing:  ../save_data/cohn-kanade-images/S066\n",
      "Processing:  ../save_data/cohn-kanade-images/S067\n",
      "Processing:  ../save_data/cohn-kanade-images/S068\n",
      "Processing:  ../save_data/cohn-kanade-images/S069\n",
      "Processing:  ../save_data/cohn-kanade-images/S070\n",
      "Processing:  ../save_data/cohn-kanade-images/S071\n",
      "Processing:  ../save_data/cohn-kanade-images/S072\n",
      "Processing:  ../save_data/cohn-kanade-images/S073\n",
      "Processing:  ../save_data/cohn-kanade-images/S074\n",
      "Processing:  ../save_data/cohn-kanade-images/S075\n",
      "Processing:  ../save_data/cohn-kanade-images/S076\n",
      "Processing:  ../save_data/cohn-kanade-images/S077\n",
      "Processing:  ../save_data/cohn-kanade-images/S078\n",
      "Processing:  ../save_data/cohn-kanade-images/S079\n",
      "Processing:  ../save_data/cohn-kanade-images/S080\n",
      "Processing:  ../save_data/cohn-kanade-images/S081\n",
      "Processing:  ../save_data/cohn-kanade-images/S082\n",
      "Processing:  ../save_data/cohn-kanade-images/S083\n",
      "Processing:  ../save_data/cohn-kanade-images/S084\n",
      "Processing:  ../save_data/cohn-kanade-images/S085\n",
      "Processing:  ../save_data/cohn-kanade-images/S086\n",
      "Processing:  ../save_data/cohn-kanade-images/S087\n",
      "Processing:  ../save_data/cohn-kanade-images/S088\n",
      "Processing:  ../save_data/cohn-kanade-images/S089\n",
      "Processing:  ../save_data/cohn-kanade-images/S090\n",
      "Processing:  ../save_data/cohn-kanade-images/S091\n",
      "Processing:  ../save_data/cohn-kanade-images/S092\n",
      "Processing:  ../save_data/cohn-kanade-images/S093\n",
      "Processing:  ../save_data/cohn-kanade-images/S094\n",
      "Processing:  ../save_data/cohn-kanade-images/S095\n",
      "Processing:  ../save_data/cohn-kanade-images/S096\n",
      "Processing:  ../save_data/cohn-kanade-images/S097\n",
      "Processing:  ../save_data/cohn-kanade-images/S098\n",
      "Processing:  ../save_data/cohn-kanade-images/S099\n",
      "Processing:  ../save_data/cohn-kanade-images/S100\n",
      "Processing:  ../save_data/cohn-kanade-images/S101\n",
      "Processing:  ../save_data/cohn-kanade-images/S102\n",
      "Processing:  ../save_data/cohn-kanade-images/S105\n",
      "Processing:  ../save_data/cohn-kanade-images/S106\n",
      "Processing:  ../save_data/cohn-kanade-images/S107\n",
      "Processing:  ../save_data/cohn-kanade-images/S108\n",
      "Processing:  ../save_data/cohn-kanade-images/S109\n",
      "Processing:  ../save_data/cohn-kanade-images/S110\n",
      "Processing:  ../save_data/cohn-kanade-images/S111\n",
      "Processing:  ../save_data/cohn-kanade-images/S112\n",
      "Processing:  ../save_data/cohn-kanade-images/S113\n",
      "Processing:  ../save_data/cohn-kanade-images/S114\n",
      "Processing:  ../save_data/cohn-kanade-images/S115\n",
      "Processing:  ../save_data/cohn-kanade-images/S116\n",
      "Processing:  ../save_data/cohn-kanade-images/S117\n",
      "Processing:  ../save_data/cohn-kanade-images/S119\n",
      "Processing:  ../save_data/cohn-kanade-images/S122\n",
      "Processing:  ../save_data/cohn-kanade-images/S124\n",
      "Processing:  ../save_data/cohn-kanade-images/S125\n",
      "Processing:  ../save_data/cohn-kanade-images/S126\n",
      "Processing:  ../save_data/cohn-kanade-images/S127\n",
      "Processing:  ../save_data/cohn-kanade-images/S128\n",
      "Processing:  ../save_data/cohn-kanade-images/S129\n",
      "Processing:  ../save_data/cohn-kanade-images/S130\n",
      "Processing:  ../save_data/cohn-kanade-images/S131\n",
      "Processing:  ../save_data/cohn-kanade-images/S132\n",
      "Processing:  ../save_data/cohn-kanade-images/S133\n",
      "Processing:  ../save_data/cohn-kanade-images/S134\n",
      "Processing:  ../save_data/cohn-kanade-images/S135\n",
      "Processing:  ../save_data/cohn-kanade-images/S136\n",
      "Processing:  ../save_data/cohn-kanade-images/S137\n",
      "Processing:  ../save_data/cohn-kanade-images/S138\n",
      "Processing:  ../save_data/cohn-kanade-images/S139\n",
      "Processing:  ../save_data/cohn-kanade-images/S147\n",
      "Processing:  ../save_data/cohn-kanade-images/S148\n",
      "Processing:  ../save_data/cohn-kanade-images/S149\n",
      "Processing:  ../save_data/cohn-kanade-images/S151\n",
      "Processing:  ../save_data/cohn-kanade-images/S154\n",
      "Processing:  ../save_data/cohn-kanade-images/S155\n",
      "Processing:  ../save_data/cohn-kanade-images/S156\n",
      "Processing:  ../save_data/cohn-kanade-images/S157\n",
      "Processing:  ../save_data/cohn-kanade-images/S158\n",
      "Processing:  ../save_data/cohn-kanade-images/S160\n",
      "Processing:  ../save_data/cohn-kanade-images/S501\n",
      "Processing:  ../save_data/cohn-kanade-images/S502\n",
      "Processing:  ../save_data/cohn-kanade-images/S503\n",
      "Processing:  ../save_data/cohn-kanade-images/S504\n",
      "Processing:  ../save_data/cohn-kanade-images/S505\n",
      "Processing:  ../save_data/cohn-kanade-images/S506\n",
      "Processing:  ../save_data/cohn-kanade-images/S895\n",
      "Processing:  ../save_data/cohn-kanade-images/S999\n",
      "\n",
      "Condensed CK+ Dataset Statistics: \n",
      "Total Number of Image Sequences: 327\n",
      "Total Number of Label Sequences: 327\n",
      "Number of sequences with correponding label .txt file: 327\n",
      "Total Number of Subjects: 118\n",
      "Number of image files: 1307\n",
      "\n",
      "Detecting and Cropping Faces\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Classifier xml file was not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/home/ini/workspace/sunbin/do-neural-networks-learn-faus-iccvw-2015/data_scripts\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Detect and crop faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mface_cropper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCKPlusFaceCropper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mface_cropper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ini/workspace/sunbin/do-neural-networks-learn-faus-iccvw-2015/data_scripts\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_and_align_all_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_list_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ini/workspace/sunbin/do-neural-networks-learn-faus-iccvw-2015/data_scripts\u001b[0m in \u001b[0;36mcrop_and_align_all_faces\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     25\u001b[0m             I, success_flag = self.process_single_image(\n\u001b[1;32m     26\u001b[0m                                                    \u001b[0mimage_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                                    output_img_size)\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mmissed_faces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ini/workspace/sunbin/do-neural-networks-learn-faus-iccvw-2015/data_scripts\u001b[0m in \u001b[0;36mprocess_single_image\u001b[0;34m(self, image_file_path, output_img_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Detect face and crop it out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mI_crop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_crop_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;31m#print I_crop.dtype, I_crop.min(), I_crop.max()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ini/workspace/sunbin/do-neural-networks-learn-faus-iccvw-2015/data_scripts\u001b[0m in \u001b[0;36mdetect_crop_face\u001b[0;34m(self, I)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0msuccess_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         face_detector = FaceDetector(scale_factor=1.3, min_neighbors=5,\n\u001b[0;32m---> 69\u001b[0;31m                                      min_size_scalar=0.5, max_size_scalar=0.8)\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ini/workspace/sunbin/do-neural-networks-learn-faus-iccvw-2015/data_scripts\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, scale_factor, min_neighbors, min_size_scalar, max_size_scalar)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Classifier xml file was not found.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Classifier xml file was not found."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         prog='make_ck_plus_dataset',\n",
    "#         formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    "#         description='Script to load, process, and split the Extended '\n",
    "#                     'Cohn-Kanade (CK+) Dataset.')\n",
    "#     parser.add_argument('-ip', '--input_path', dest='input_path',\n",
    "#                         help='Path specifying location of downloaded '\n",
    "#                              'CK+ files.')\n",
    "#     parser.add_argument('-sp', '--save_path', dest='save_path',\n",
    "#                         default='./CK_PLUS_HERE',\n",
    "#                         help='Path specifying where to save \\\n",
    "#                               the pre-processed dataset and the \\\n",
    "#                               output (.npy) files.')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     print('\\n================================================================')\n",
    "#     print('                Extended Cohn-Kanade Dataset Manager              ')\n",
    "#     print('================================================================\\n')\n",
    "\n",
    "    input_path = '../data'\n",
    "    save_path = '../save_data'\n",
    "\n",
    "    # Condense CK+ dataset\n",
    "    condenser = CKPlusCondenser(input_path, save_path)\n",
    "    condenser.run()\n",
    "\n",
    "    # Detect and crop faces\n",
    "    face_cropper = CKPlusFaceCropper(save_path)\n",
    "    face_cropper.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving CK+ images and labels to .npy files.\n",
      "Subject: 0 - S005\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m./\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save out CK+ .npy files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnumpy_file_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCKPlusNumpyFileGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnumpy_file_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\nSuccessfully pre-processed the Extended Cohn-Kanade Dataset!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m./\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfacs_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                                                 num_samples)\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m./\u001b[0m in \u001b[0;36mmake_data_label_mats\u001b[0;34m(self, all_images_path, all_labels_path, all_facs_path, num_samples)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mlabel_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mfacs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_facs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_facs_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mfacs_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m./\u001b[0m in \u001b[0;36mread_facs\u001b[0;34m(self, all_facs_path, subj, seq)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mfacs_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mfacs_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacs_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# Save out CK+ .npy files\n",
    "numpy_file_generator = CKPlusNumpyFileGenerator(save_path)\n",
    "numpy_file_generator.run()\n",
    "\n",
    "print '\\nSuccessfully pre-processed the Extended Cohn-Kanade Dataset!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
