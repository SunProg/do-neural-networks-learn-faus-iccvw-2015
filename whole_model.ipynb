{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import  Input, Dense, Conv2D, Dropout, Flatten, MaxPooling2D, LSTM\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    k = float(np.random.rand()*1+0.2)\n",
    "    print ('## k = %.3f' % k)\n",
    "    winit1 = k/np.sqrt(5*5*1)\n",
    "    winit2 = k/np.sqrt(5*5*64)\n",
    "    winit3 = k/np.sqrt(5*5*128)\n",
    "    \n",
    "    cnn_input = Input(shape=(1,96,96))\n",
    "    conv1 = Conv2D(filters=64, kernel_size=5, padding='same',\n",
    "                    data_format='channels_first',\n",
    "                    use_bias=False, \n",
    "                    kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=winit1),\n",
    "                    activation='relu')(cnn_input)\n",
    "    maxpool1 = MaxPooling2D(pool_size=2, strides=(2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filters=128, kernel_size=5, padding='same',\n",
    "                    data_format='channels_first',\n",
    "                    use_bias=False,\n",
    "                    kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=winit2),\n",
    "                    activation='relu')(maxpool1)\n",
    "    maxpool2 = MaxPooling2D(pool_size=2, strides=(2,2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(filters=256, kernel_size=5, padding='same',\n",
    "                    data_format='channels_first',\n",
    "                    use_bias=False,\n",
    "                    kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=winit3),\n",
    "                    activation='relu')(maxpool2)\n",
    "    maxpool3 = MaxPooling2D(pool_size=12, strides=(12,12))(conv3)\n",
    "    flatten = Flatten()(maxpool3)\n",
    "\n",
    "    winitD1 = k/np.sqrt(4032)\n",
    "    winitD2 = k/np.sqrt(300)\n",
    "    dropout = Dropout(0.5)(flatten)\n",
    "    dense1 = Dense(300, activation='relu',\n",
    "                    kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05),\n",
    "                    bias_initializer='Ones')(dropout)\n",
    "\n",
    "    cnn_output = Dense(8, activation='softmax',\n",
    "    kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=winitD2),\n",
    "    bias_initializer='Zeros')(dense1)\n",
    "\n",
    "    cnn_model = Model(inputs=cnn_input, outputs=cnn_output)\n",
    "    print(cnn_model.summary())\n",
    "    \n",
    "    # compile the model\n",
    "    sgd = keras.optimizers.SGD(lr=0.01, decay=1e-5, momentum=0.9)\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer=sgd,\n",
    "             metrics=['accuracy'])\n",
    "    \n",
    "    # LSTM Model\n",
    "    rnn_input = Input(shape=(15, 64))\n",
    "    lstm1 = LSTM(250, return_sequences=True)(rnn_input)\n",
    "    feature_and_class = Input(shape=(15,4040,))\n",
    "    merge = concatenate([lstm1, feature_and_class])\n",
    "    lstm2 = LSTM(250, return_sequences=True)(merge)\n",
    "    rnn_output = Dense(64, activation='softmax')(lstm2)\n",
    "    \n",
    "    rnn_model = Model(inputs=[rnn_input, feature_and_class], outputs=rnn_output)\n",
    "    print(rnn_model.summary())\n",
    "    rnn_model.compile(loss='categorical_crossentropy', optimizer=sgd,\n",
    "             metrics=['accuracy'])\n",
    "    \n",
    "    return cnn_model, rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path='./npy_files'):\n",
    "    X = np.load(os.path.join(dataset_path,'X.npy'))\n",
    "    y = np.load(os.path.join(dataset_path,'y.npy'))\n",
    "    folds = np.load(os.path.join(dataset_path,'folds.npy'))\n",
    "    feature_class = np.load(os.path.join(dataset_path, 'feature_class.npy'))\n",
    "    facs = np.load(os.path.join(dataset_path,'np_facs.npy'))\n",
    "\n",
    "    # rescale [0,255] -> [0,2]    \n",
    "    X = X.astype('float32')/255*2\n",
    "\n",
    "    # one-hot encode the labels\n",
    "    num_classes = len(np.unique(y))\n",
    "    y = keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "    return X, y, folds, feature_class, facs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_facs_y(facs):\n",
    "    facs_y = []\n",
    "    for inst in facs:\n",
    "        temp = list(inst)[:-1]\n",
    "        temp.append(list(np.zeros(64)))\n",
    "        facs_y.append(temp)\n",
    "    facs_y = np.array(facs_y)\n",
    "    \n",
    "    return facs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cv_folds(X, y, feature_class, facs, folds, fold_num):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    feature_class_train = []\n",
    "    facs_train = []\n",
    "    \n",
    "    X_valid = []\n",
    "    y_valid = []\n",
    "    feature_class_valid = []\n",
    "    facs_valid = []\n",
    "    \n",
    "    for index, fold in enumerate(folds):\n",
    "        if fold == fold_num:\n",
    "            X_valid.append(X[index])\n",
    "            y_valid.append(y[index])\n",
    "            feature_class_valid.append(feature_class[index])\n",
    "            facs_valid.append(facs[index])\n",
    "        else:\n",
    "            X_train.append(X[index])\n",
    "            y_train.append(y[index])\n",
    "            feature_class_train.append(feature_class[index])\n",
    "            facs_train.append(facs[index])\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_valid = np.array(X_valid)\n",
    "    y_valid = np.array(y_valid)\n",
    "    \n",
    "    feature_class_train = np.array(feature_class_train)\n",
    "    feature_class_valid = np.array(feature_class_valid)\n",
    "\n",
    "    facs_train = np.array(facs_train)\n",
    "    facs_valid = np.array(facs_valid)\n",
    "    facs_y_train = make_facs_y(facs_train)\n",
    "    facs_y_valid = make_facs_y(facs_valid)\n",
    "\n",
    "    return (X_train, y_train, \n",
    "            X_valid, y_valid,\n",
    "            feature_class_train, feature_class_valid,\n",
    "            facs_train, facs_valid,\n",
    "            facs_y_train, facs_y_valid\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cnn_model(model_path='./result/'):\n",
    "    with open(os.path.join(model_path, 'model_architecture.json'), 'r') as f:\n",
    "        model = model_from_json(f.read())\n",
    "\n",
    "    model.load_weights(os.path.join(model_path, 'weights-42-0.90.hdf5'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## k = 0.779\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 96, 96)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 96, 96)        1600      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 48, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 48, 96)       102400    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 24, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 24, 96)       409600    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 21, 2, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4032)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4032)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               1209900   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 2408      \n",
      "=================================================================\n",
      "Total params: 1,725,908\n",
      "Trainable params: 1,725,908\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 15, 64)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 15, 250)      315000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 15, 4040)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 15, 4290)     0           lstm_1[0][0]                     \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 15, 250)      4541000     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 15, 64)       16064       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,872,064\n",
      "Trainable params: 4,872,064\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X, y, folds, feature_class, facs = load_data('./save_data/npy_files/')\n",
    "\n",
    "_, rnn_model = make_model()\n",
    "cnn_model = load_cnn_model('./result/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, feature_class_train, feature_class_valid,facs_train, facs_valid,facs_y_train, facs_y_valid = make_cv_folds(X, y, feature_class,\n",
    "                                            facs, folds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175 samples, validate on 132 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "result_path_folder = './result/rnn_model'\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "filepath = os.path.join(result_path_folder,filepath)\n",
    "checkpointer = ModelCheckpoint(filepath=filepath,\n",
    "                        monitor='val_acc',\n",
    "                        verbose=1, save_best_only=True)\n",
    " \n",
    "hist = rnn_model.fit([facs_train,feature_class_train ], facs_y_train, batch_size=64, epochs=100,\n",
    "            validation_data=([facs_valid, feature_class_valid], facs_y_valid),\n",
    "            callbacks=[checkpointer], verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model_json = rnn_model.to_json()\n",
    "with open(\"./result/rnn_model/model_architecture.json\", \"w\") as json_file:\n",
    "    json_file.write(rnn_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = 'result/rnn_prototype'\n",
    "hist = []\n",
    "# CV Training\n",
    "for times in range(10):\n",
    "    result_path_times = os.path.join(result_path, str(times))\n",
    "    hist_folds = []\n",
    "    for val_fold in range(10):\n",
    "        result_path_folds = os.path.join(result_path_times, str(val_fold))\n",
    "        X_train, y_train, X_valid, y_valid = make_cv_folds(X, y, folds, val_fold)\n",
    "\n",
    "        print('X_train shape :', X_train.shape)\n",
    "        print('y_train shape :', y_train.shape)\n",
    "\n",
    "\n",
    "        # printing number of training, validation, and test images\n",
    "        print(X_train.shape[0], 'train samples')\n",
    "        #print(X_test.shape[0], 'test samples')\n",
    "        print(X_valid.shape[0], 'validation samples')\n",
    "        #X_test = X_test.astype('float32')/255\n",
    "        model = make_model()\n",
    "        filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "        filepath = os.path.join(result_path_folds,filepath)\n",
    "        checkpointer = ModelCheckpoint(filepath=filepath,\n",
    "                                monitor='val_acc',\n",
    "                                verbose=1, save_best_only=True)\n",
    "\n",
    "        hist_folds.append( model.fit(X_train, y_train, batch_size=64, epochs=50,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpointer], verbose=2, shuffle=True) )\n",
    "    hist.append(hist_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Data loading\n",
    "    dataset_path = 'save_data/npy_files'\n",
    "    result_path = 'result/'\n",
    "    X = np.load(os.path.join(dataset_path,'X.npy'))\n",
    "    y = np.load(os.path.join(dataset_path,'y.npy'))\n",
    "    folds = np.load(os.path.join(dataset_path,'folds.npy'))\n",
    "    \n",
    "    # rescale [0,255] -> [0,2]    \n",
    "    X = X.astype('float32')/255*2\n",
    "\n",
    "    # one-hot encode the labels\n",
    "    num_classes = len(np.unique(y))\n",
    "    y = keras.utils.to_categorical(y, num_classes)\n",
    "    \n",
    "    \n",
    "\n",
    "    hist = []\n",
    "    # CV Training\n",
    "    for times in range(10):\n",
    "        result_path_times = os.path.join(result_path, str(times))\n",
    "        hist_folds = []\n",
    "        for val_fold in range(10):\n",
    "            result_path_folds = os.path.join(result_path_times, str(val_fold))\n",
    "            X_train, y_train, X_valid, y_valid = make_cv_folds(X, y, folds, val_fold)\n",
    "            \n",
    "            print('X_train shape :', X_train.shape)\n",
    "            print('y_train shape :', y_train.shape)\n",
    "            \n",
    "            \n",
    "            # printing number of training, validation, and test images\n",
    "            print(X_train.shape[0], 'train samples')\n",
    "            #print(X_test.shape[0], 'test samples')\n",
    "            print(X_valid.shape[0], 'validation samples')\n",
    "            #X_test = X_test.astype('float32')/255\n",
    "            model = make_model()\n",
    "            filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "            filepath = os.path.join(result_path_folds,filepath)\n",
    "            checkpointer = ModelCheckpoint(filepath=filepath,\n",
    "                                    monitor='val_acc',\n",
    "                                    verbose=1, save_best_only=True)\n",
    "\n",
    "            hist_folds.append( model.fit(X_train, y_train, batch_size=64, epochs=50,\n",
    "                        validation_data=(X_valid, y_valid),\n",
    "                        callbacks=[checkpointer], verbose=2, shuffle=True) )\n",
    "        hist.append(hist_folds)\n",
    "    \n",
    "    \n",
    "  \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
